{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 370,
      "metadata": {
        "id": "bC0Ezn_z2r2R"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pip install ludwig[full]"
      ],
      "metadata": {
        "id": "hk5Ct8hd3EwB"
      },
      "execution_count": 371,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://raw.githubusercontent.com/john-adeojo/walmartdata/main/Walmart%20Store/TRAIN.csv'\n",
        "df = pd.read_csv(url)\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "yPOPbzsB3Jvm",
        "outputId": "8c9549f4-5f66-4714-da34-efee2b6efc5d"
      },
      "execution_count": 372,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         ID  Store_id Store_Type Location_Type Region_Code        Date  \\\n",
              "0  T1000001         1         S1            L3          R1  2018-01-01   \n",
              "1  T1000002       253         S4            L2          R1  2018-01-01   \n",
              "2  T1000003       252         S3            L2          R1  2018-01-01   \n",
              "3  T1000004       251         S2            L3          R1  2018-01-01   \n",
              "4  T1000005       250         S2            L3          R4  2018-01-01   \n",
              "\n",
              "   Holiday Discount  #Order     Sales  \n",
              "0        1      Yes       9   7011.84  \n",
              "1        1      Yes      60  51789.12  \n",
              "2        1      Yes      42  36868.20  \n",
              "3        1      Yes      23  19715.16  \n",
              "4        1      Yes      62  45614.52  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fb64a4c6-a36c-4f87-9146-435c3f95df5a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Store_id</th>\n",
              "      <th>Store_Type</th>\n",
              "      <th>Location_Type</th>\n",
              "      <th>Region_Code</th>\n",
              "      <th>Date</th>\n",
              "      <th>Holiday</th>\n",
              "      <th>Discount</th>\n",
              "      <th>#Order</th>\n",
              "      <th>Sales</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>T1000001</td>\n",
              "      <td>1</td>\n",
              "      <td>S1</td>\n",
              "      <td>L3</td>\n",
              "      <td>R1</td>\n",
              "      <td>2018-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>Yes</td>\n",
              "      <td>9</td>\n",
              "      <td>7011.84</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>T1000002</td>\n",
              "      <td>253</td>\n",
              "      <td>S4</td>\n",
              "      <td>L2</td>\n",
              "      <td>R1</td>\n",
              "      <td>2018-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>Yes</td>\n",
              "      <td>60</td>\n",
              "      <td>51789.12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>T1000003</td>\n",
              "      <td>252</td>\n",
              "      <td>S3</td>\n",
              "      <td>L2</td>\n",
              "      <td>R1</td>\n",
              "      <td>2018-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>Yes</td>\n",
              "      <td>42</td>\n",
              "      <td>36868.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>T1000004</td>\n",
              "      <td>251</td>\n",
              "      <td>S2</td>\n",
              "      <td>L3</td>\n",
              "      <td>R1</td>\n",
              "      <td>2018-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>Yes</td>\n",
              "      <td>23</td>\n",
              "      <td>19715.16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>T1000005</td>\n",
              "      <td>250</td>\n",
              "      <td>S2</td>\n",
              "      <td>L3</td>\n",
              "      <td>R4</td>\n",
              "      <td>2018-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>Yes</td>\n",
              "      <td>62</td>\n",
              "      <td>45614.52</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fb64a4c6-a36c-4f87-9146-435c3f95df5a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fb64a4c6-a36c-4f87-9146-435c3f95df5a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fb64a4c6-a36c-4f87-9146-435c3f95df5a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 372
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['Date'] = pd.to_datetime(df['Date'])\n",
        "df_original = df.copy()"
      ],
      "metadata": {
        "id": "Db8K8bTSCtoc"
      },
      "execution_count": 373,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data set splitting\n",
        "import numpy as np\n",
        "import hashlib\n",
        "\n",
        "def split_data(df):\n",
        "  # Create a new column 'hash_val' that is the hash of the 'Store_id' column\n",
        "  df['hash_val'] = df['Store_id'].apply(lambda x: int(hashlib.sha256(str(x).encode('utf-8')).hexdigest(), 16))\n",
        "\n",
        "  # Use the 'hash_val' column to create a boolean mask for the holdout set\n",
        "  is_holdout = df['hash_val'] % 10 < 2  # Approximately 20% will be in the holdout set\n",
        "\n",
        "  # Create the holdout and train sets\n",
        "  holdout_set = df[is_holdout].copy()\n",
        "  train_set = df[~is_holdout].copy()\n",
        "\n",
        "  # Add a 'set' column to each set\n",
        "  holdout_set['set'] = 'hold_out'\n",
        "  train_set['set'] = 'train'\n",
        "\n",
        "  df_predictions = pd.concat([holdout_set, train_set], axis=0)\n",
        "\n",
        "  return train_set, df_predictions\n",
        "\n",
        "train_set, df_predictions = split_data(df)"
      ],
      "metadata": {
        "id": "_WKByFKMH0Zx"
      },
      "execution_count": 374,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df = train_set\n",
        "\n",
        "def transform_data(df):\n",
        "\n",
        "  # Convert 'Discount' column to binary\n",
        "  df['Discount'] = df['Discount'].map({'Yes': 1, 'No': 0}).astype(int)\n",
        "\n",
        "  # Convert 'Date' to datetime\n",
        "  df['Date'] = pd.to_datetime(df['Date'])\n",
        "\n",
        "  # Create 'DayOfWeek' and 'MonthOfYear'\n",
        "  df['DayOfWeek'] = df['Date'].dt.dayofweek\n",
        "  df['MonthOfYear'] = df['Date'].dt.month\n",
        "\n",
        "  # Sort DataFrame by 'Store_id' and 'Date'\n",
        "  df.sort_values(['Store_id', 'Date'], inplace=True)\n",
        "\n",
        "  # List of sequence features\n",
        "  sequence_features = ['Sales', '#Order', 'Discount', 'DayOfWeek', 'MonthOfYear', 'Holiday']\n",
        "\n",
        "  # Window size for features and labels (3 days for example)\n",
        "  feature_window_size = 30\n",
        "  label_window_size = 7\n",
        "\n",
        "  # List to store sequences\n",
        "  sequences = []\n",
        "\n",
        "  # Generate sequences for each store\n",
        "  for store_id in df['Store_id'].unique():\n",
        "      df_store = df[df['Store_id'] == store_id]\n",
        "\n",
        "      # Check if store has enough data for the window\n",
        "      if len(df_store) >= (feature_window_size + label_window_size):\n",
        "          sequence = {feature: ' '.join(map(str, df_store[feature].iloc[-feature_window_size-label_window_size:-label_window_size].values)) for feature in sequence_features}\n",
        "          sequence['Sales_sequence_label'] = ' '.join(map(str, df_store['Sales'].iloc[-label_window_size:].values))\n",
        "          sequence['Sales_sequence_label_date'] = ' '.join(map(str, df_store['Date'].iloc[-label_window_size:].dt.date.values))\n",
        "          sequence['Store_id'] = store_id\n",
        "          sequences.append(sequence)\n",
        "\n",
        "  # Convert list of sequences to DataFrame\n",
        "  df_sequences = pd.DataFrame(sequences)\n",
        "\n",
        "  df_sequences.rename(columns={'#Order': 'Order'}, inplace=True)\n",
        "\n",
        "  # Split 'Sales_sequence_label' and 'Sales_sequence_label_date' into list of values\n",
        "  df_sequences['Sales_sequence_label'] = df_sequences['Sales_sequence_label'].str.split(' ')\n",
        "  df_sequences['Sales_sequence_label_date'] = df_sequences['Sales_sequence_label_date'].str.split(' ')\n",
        "\n",
        "  # Determine the maximum length of sales sequences\n",
        "  max_length = df_sequences['Sales_sequence_label'].str.len().max()\n",
        "\n",
        "  # Convert list into separate columns\n",
        "  sales_columns = df_sequences['Sales_sequence_label'].apply(pd.Series)\n",
        "  sales_columns_date = df_sequences['Sales_sequence_label_date'].apply(pd.Series)\n",
        "\n",
        "  # Rename columns\n",
        "  sales_columns = sales_columns.rename(columns = lambda x : 'Sales_sequence_label_' + str(df_sequences['Sales_sequence_label_date'].iloc[0][x]))\n",
        "\n",
        "  # Concatenate the sales_columns dataframe with the original dataframe\n",
        "  df_sequences = pd.concat([df_sequences[:], sales_columns[:]], axis=1)\n",
        "\n",
        "  # Drop the original 'Sales_sequence_label' and 'Sales_sequence_label_date' columns\n",
        "  df_sequences = df_sequences.drop(['Sales_sequence_label', 'Sales_sequence_label_date'], axis=1)\n",
        "\n",
        "  return df_sequences\n",
        "\n",
        "df_sequences = transform_data(train_set)\n",
        "df_predictions = transform_data(df_predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ehheiLN8Cd5J",
        "outputId": "86126490-4f5a-400d-cda0-e127853bfd12"
      },
      "execution_count": 375,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               Sales  \\\n",
              "0  27207.0 14484.0 56808.0 27330.0 36516.0 15531....   \n",
              "1  61110.0 28419.0 96768.0 61542.0 69372.0 46215....   \n",
              "2  22365.0 38832.0 28824.0 76044.0 33642.0 52155....   \n",
              "3  34671.0 25866.0 69819.0 46002.0 46914.0 26733....   \n",
              "4  17487.0 64281.0 26178.0 59190.0 22779.0 84000....   \n",
              "\n",
              "                                               Order  \\\n",
              "0  53 26 100 49 65 27 97 53 80 94 116 88 92 35 34...   \n",
              "1  122 56 186 118 136 89 284 169 214 229 258 207 ...   \n",
              "2  39 70 53 139 59 90 77 84 90 116 52 72 62 63 59...   \n",
              "3  61 45 115 77 78 45 125 78 91 103 102 88 100 60...   \n",
              "4  35 123 50 111 43 153 74 123 119 157 168 152 55...   \n",
              "\n",
              "                                            Discount  \\\n",
              "0  0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 1 1 1 ...   \n",
              "1  0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 1 1 1 ...   \n",
              "2  0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 1 1 1 1 1 0 ...   \n",
              "3  0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 1 1 1 ...   \n",
              "4  0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 1 1 1 1 ...   \n",
              "\n",
              "                                           DayOfWeek  \\\n",
              "0  3 4 5 6 0 1 2 3 4 5 6 0 1 2 3 4 5 6 0 1 2 3 4 ...   \n",
              "1  3 4 5 6 0 1 2 3 4 5 6 0 1 2 3 4 5 6 0 1 2 3 4 ...   \n",
              "2  3 4 5 6 0 1 2 3 4 5 6 0 1 2 3 4 5 6 0 1 2 3 4 ...   \n",
              "3  3 4 5 6 0 1 2 3 4 5 6 0 1 2 3 4 5 6 0 1 2 3 4 ...   \n",
              "4  3 4 5 6 0 1 2 3 4 5 6 0 1 2 3 4 5 6 0 1 2 3 4 ...   \n",
              "\n",
              "                                         MonthOfYear  \\\n",
              "0  4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 ...   \n",
              "1  4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 ...   \n",
              "2  4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 ...   \n",
              "3  4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 ...   \n",
              "4  4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 ...   \n",
              "\n",
              "                                             Holiday  Store_id  \\\n",
              "0  0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 ...         1   \n",
              "1  0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 ...         3   \n",
              "2  0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 ...         4   \n",
              "3  0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 ...         5   \n",
              "4  0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 ...         6   \n",
              "\n",
              "  Sales_sequence_label_2019-05-25 Sales_sequence_label_2019-05-26  \\\n",
              "0                         40554.0                         25035.0   \n",
              "1                         94548.0                         66036.0   \n",
              "2                         49185.0                         53550.0   \n",
              "3                         55830.0                         45726.0   \n",
              "4                         27150.0                         60165.0   \n",
              "\n",
              "  Sales_sequence_label_2019-05-27 Sales_sequence_label_2019-05-28  \\\n",
              "0                         33075.0                         37317.0   \n",
              "1                         69930.0                         72540.0   \n",
              "2                         48219.0                         55194.0   \n",
              "3                         48849.0                         46806.0   \n",
              "4                         52029.0                         53100.0   \n",
              "\n",
              "  Sales_sequence_label_2019-05-29 Sales_sequence_label_2019-05-30  \\\n",
              "0                         44652.0                         42387.0   \n",
              "1                         76428.0                         78135.0   \n",
              "2                         25938.0                         37119.0   \n",
              "3                         43197.0                         46737.0   \n",
              "4                         67809.0                         72012.0   \n",
              "\n",
              "  Sales_sequence_label_2019-05-31  \n",
              "0                        39843.78  \n",
              "1               75790.95000000001  \n",
              "2                        36747.81  \n",
              "3                        44867.52  \n",
              "4                        67691.28  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d686af32-8bce-49c4-bf1f-d68452c07292\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sales</th>\n",
              "      <th>Order</th>\n",
              "      <th>Discount</th>\n",
              "      <th>DayOfWeek</th>\n",
              "      <th>MonthOfYear</th>\n",
              "      <th>Holiday</th>\n",
              "      <th>Store_id</th>\n",
              "      <th>Sales_sequence_label_2019-05-25</th>\n",
              "      <th>Sales_sequence_label_2019-05-26</th>\n",
              "      <th>Sales_sequence_label_2019-05-27</th>\n",
              "      <th>Sales_sequence_label_2019-05-28</th>\n",
              "      <th>Sales_sequence_label_2019-05-29</th>\n",
              "      <th>Sales_sequence_label_2019-05-30</th>\n",
              "      <th>Sales_sequence_label_2019-05-31</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>27207.0 14484.0 56808.0 27330.0 36516.0 15531....</td>\n",
              "      <td>53 26 100 49 65 27 97 53 80 94 116 88 92 35 34...</td>\n",
              "      <td>0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 1 1 1 ...</td>\n",
              "      <td>3 4 5 6 0 1 2 3 4 5 6 0 1 2 3 4 5 6 0 1 2 3 4 ...</td>\n",
              "      <td>4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 ...</td>\n",
              "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 ...</td>\n",
              "      <td>1</td>\n",
              "      <td>40554.0</td>\n",
              "      <td>25035.0</td>\n",
              "      <td>33075.0</td>\n",
              "      <td>37317.0</td>\n",
              "      <td>44652.0</td>\n",
              "      <td>42387.0</td>\n",
              "      <td>39843.78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>61110.0 28419.0 96768.0 61542.0 69372.0 46215....</td>\n",
              "      <td>122 56 186 118 136 89 284 169 214 229 258 207 ...</td>\n",
              "      <td>0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 1 1 1 ...</td>\n",
              "      <td>3 4 5 6 0 1 2 3 4 5 6 0 1 2 3 4 5 6 0 1 2 3 4 ...</td>\n",
              "      <td>4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 ...</td>\n",
              "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 ...</td>\n",
              "      <td>3</td>\n",
              "      <td>94548.0</td>\n",
              "      <td>66036.0</td>\n",
              "      <td>69930.0</td>\n",
              "      <td>72540.0</td>\n",
              "      <td>76428.0</td>\n",
              "      <td>78135.0</td>\n",
              "      <td>75790.95000000001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>22365.0 38832.0 28824.0 76044.0 33642.0 52155....</td>\n",
              "      <td>39 70 53 139 59 90 77 84 90 116 52 72 62 63 59...</td>\n",
              "      <td>0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 1 1 1 1 1 0 ...</td>\n",
              "      <td>3 4 5 6 0 1 2 3 4 5 6 0 1 2 3 4 5 6 0 1 2 3 4 ...</td>\n",
              "      <td>4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 ...</td>\n",
              "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 ...</td>\n",
              "      <td>4</td>\n",
              "      <td>49185.0</td>\n",
              "      <td>53550.0</td>\n",
              "      <td>48219.0</td>\n",
              "      <td>55194.0</td>\n",
              "      <td>25938.0</td>\n",
              "      <td>37119.0</td>\n",
              "      <td>36747.81</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>34671.0 25866.0 69819.0 46002.0 46914.0 26733....</td>\n",
              "      <td>61 45 115 77 78 45 125 78 91 103 102 88 100 60...</td>\n",
              "      <td>0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 1 1 1 ...</td>\n",
              "      <td>3 4 5 6 0 1 2 3 4 5 6 0 1 2 3 4 5 6 0 1 2 3 4 ...</td>\n",
              "      <td>4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 ...</td>\n",
              "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 ...</td>\n",
              "      <td>5</td>\n",
              "      <td>55830.0</td>\n",
              "      <td>45726.0</td>\n",
              "      <td>48849.0</td>\n",
              "      <td>46806.0</td>\n",
              "      <td>43197.0</td>\n",
              "      <td>46737.0</td>\n",
              "      <td>44867.52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>17487.0 64281.0 26178.0 59190.0 22779.0 84000....</td>\n",
              "      <td>35 123 50 111 43 153 74 123 119 157 168 152 55...</td>\n",
              "      <td>0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 1 1 1 1 ...</td>\n",
              "      <td>3 4 5 6 0 1 2 3 4 5 6 0 1 2 3 4 5 6 0 1 2 3 4 ...</td>\n",
              "      <td>4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 ...</td>\n",
              "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 ...</td>\n",
              "      <td>6</td>\n",
              "      <td>27150.0</td>\n",
              "      <td>60165.0</td>\n",
              "      <td>52029.0</td>\n",
              "      <td>53100.0</td>\n",
              "      <td>67809.0</td>\n",
              "      <td>72012.0</td>\n",
              "      <td>67691.28</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d686af32-8bce-49c4-bf1f-d68452c07292')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d686af32-8bce-49c4-bf1f-d68452c07292 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d686af32-8bce-49c4-bf1f-d68452c07292');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 375
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "\n",
        "# # Convert 'Discount' column to binary\n",
        "# df['Discount'] = df['Discount'].map({'Yes': 1, 'No': 0}).astype(int)\n",
        "\n",
        "# # Convert 'Date' to datetime\n",
        "# df['Date'] = pd.to_datetime(df['Date'])\n",
        "\n",
        "# # Create 'DayOfWeek' and 'MonthOfYear'\n",
        "# df['DayOfWeek'] = df['Date'].dt.dayofweek\n",
        "# df['MonthOfYear'] = df['Date'].dt.month\n",
        "\n",
        "# # Sort DataFrame by 'Store_id' and 'Date'\n",
        "# df.sort_values(['Store_id', 'Date'], inplace=True)\n",
        "\n",
        "# # List of sequence features\n",
        "# sequence_features = ['Sales', '#Order', 'Discount', 'DayOfWeek', 'MonthOfYear', 'Holiday']\n",
        "\n",
        "# # Window size for features and labels (3 days for example)\n",
        "# feature_window_size = 30\n",
        "# label_window_size = 7\n",
        "\n",
        "# # List to store sequences\n",
        "# sequences = []\n",
        "\n",
        "# # Generate sequences for each store\n",
        "# for store_id in df['Store_id'].unique():\n",
        "#     df_store = df[df['Store_id'] == store_id]\n",
        "\n",
        "#     # Check if store has enough data for the window\n",
        "#     if len(df_store) >= (feature_window_size + label_window_size):\n",
        "#         sequence = {feature: ' '.join(map(str, df_store[feature].iloc[-feature_window_size-label_window_size:-label_window_size].values)) for feature in sequence_features}\n",
        "#         sequence['Sales_sequence_label'] = ' '.join(map(str, df_store['Sales'].iloc[-label_window_size:].values))\n",
        "#         sequence['Store_id'] = store_id\n",
        "#         sequences.append(sequence)\n",
        "\n",
        "# # Convert list of sequences to DataFrame\n",
        "# df_sequences = pd.DataFrame(sequences)\n",
        "\n",
        "# df_sequences.rename(columns={'#Order': 'Order'}, inplace=True)\n",
        "# # df_sequences\n",
        "\n",
        "# # Split 'Sales_sequence_label' into list of values\n",
        "# df_sequences['Sales_sequence_label'] = df_sequences['Sales_sequence_label'].str.split(' ')\n",
        "\n",
        "# # Determine the maximum length of sales sequences\n",
        "# max_length = df_sequences['Sales_sequence_label'].str.len().max()\n",
        "\n",
        "# # Convert list into separate columns\n",
        "# sales_columns = df_sequences['Sales_sequence_label'].apply(pd.Series)\n",
        "\n",
        "# # Rename columns\n",
        "# sales_columns = sales_columns.rename(columns = lambda x : 'Sales_sequence_label_' + str(x))\n",
        "\n",
        "# # Concatenate the sales_columns dataframe with the original dataframe\n",
        "# df_sequences = pd.concat([df_sequences[:], sales_columns[:]], axis=1)\n",
        "\n",
        "# # Drop the original 'Sales_sequence_label' column\n",
        "# df_sequences = df_sequences.drop('Sales_sequence_label', axis=1)\n",
        "# df_sequences\n"
      ],
      "metadata": {
        "id": "fMcLbfum58db"
      },
      "execution_count": 376,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plotting time series for store ID 1"
      ],
      "metadata": {
        "id": "alhGDYlvkHWh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "# import plotly.express as px\n",
        "# import plotly.graph_objects as go\n",
        "\n",
        "# def plot_data(df, column):\n",
        "#     fig = px.line(df, x='Date', y=column)\n",
        "#     fig.update_xaxes(tickangle=90)  # Rotate x-axis labels\n",
        "#     fig.show()\n",
        "\n",
        "# plot_data(df_example_store, 'Sales')\n",
        "# plot_data(df_example_store, '#Order')"
      ],
      "metadata": {
        "id": "Idl9-9g9g36V"
      },
      "execution_count": 377,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Data set splitting\n",
        "# import numpy as np\n",
        "# import hashlib\n",
        "\n",
        "# def split_data(df):\n",
        "#   # Create a new column 'hash_val' that is the hash of the 'Store_id' column\n",
        "#   df['hash_val'] = df['Store_id'].apply(lambda x: int(hashlib.sha256(str(x).encode('utf-8')).hexdigest(), 16))\n",
        "\n",
        "#   # Use the 'hash_val' column to create a boolean mask for the holdout set\n",
        "#   is_holdout = df['hash_val'] % 10 < 2  # Approximately 20% will be in the holdout set\n",
        "\n",
        "#   # Create the holdout and train sets\n",
        "#   holdout_set = df[is_holdout].copy()\n",
        "#   train_set = df[~is_holdout].copy()\n",
        "\n",
        "#   # Add a 'set' column to each set\n",
        "#   holdout_set['set'] = 'hold_out'\n",
        "#   train_set['set'] = 'train'\n",
        "\n",
        "#   return holdout_set, train_set"
      ],
      "metadata": {
        "id": "kRVfqP_cw7qc"
      },
      "execution_count": 378,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# holdout_set"
      ],
      "metadata": {
        "id": "oNmgBRbopeq4"
      },
      "execution_count": 379,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenate the holdout and train sets\n",
        "# df_predictions = pd.concat([holdout_set, train_set], axis=0)\n",
        "# df_predictions.head()"
      ],
      "metadata": {
        "id": "_KEx3dFYxswu"
      },
      "execution_count": 380,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import yaml\n",
        "from ludwig.api import LudwigModel\n",
        "\n",
        "# URL of the raw YAML file in the GitHub repository\n",
        "url = 'https://raw.githubusercontent.com/john-adeojo/walmartdata/main/Walmart%20Store/timeseries.yaml'\n",
        "\n",
        "# Send a GET request to the URL\n",
        "response = requests.get(url)\n",
        "\n",
        "# Raise an exception if the request was unsuccessful\n",
        "response.raise_for_status()\n",
        "\n",
        "# Load the YAML data from the response text\n",
        "config = yaml.safe_load(response.text)\n",
        "\n",
        "# Now you can use the config dictionary to initialize the Ludwig model\n",
        "model = LudwigModel(config=config)\n",
        "results = model.train(dataset=df_sequences)"
      ],
      "metadata": {
        "id": "HLxRycJVNnB0"
      },
      "execution_count": 381,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions, _ = model.predict(dataset=df_predictions)\n",
        "predictions.head()"
      ],
      "metadata": {
        "id": "wQ-xuoep361z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        },
        "outputId": "3b1191d5-5907-4052-a0a1-d3db72a8cd81"
      },
      "execution_count": 382,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3802\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3803\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Order'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-382-f008d7e6946c>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_predictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ludwig/api.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, dataset, data_format, split, batch_size, skip_save_unprocessed_output, skip_save_predictions, output_directory, return_type, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    869\u001b[0m         \u001b[0;31m# preprocessing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Preprocessing\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m         dataset, _ = preprocess_for_prediction(  # TODO (Connor): Refactor to use self.config_obj\n\u001b[0m\u001b[1;32m    872\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m             \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ludwig/data/preprocessing.py\u001b[0m in \u001b[0;36mpreprocess_for_prediction\u001b[0;34m(config, dataset, training_set_metadata, data_format, split, include_outputs, backend, callbacks)\u001b[0m\n\u001b[1;32m   2118\u001b[0m             \u001b[0mtraining_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_set_metadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocessed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2120\u001b[0;31m         processed = data_format_processor.preprocess_for_prediction(\n\u001b[0m\u001b[1;32m   2121\u001b[0m             \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocessing_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_set_metadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2122\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ludwig/data/preprocessing.py\u001b[0m in \u001b[0;36mpreprocess_for_prediction\u001b[0;34m(dataset, features, preprocessing_params, training_set_metadata, backend, callbacks)\u001b[0m\n\u001b[1;32m    262\u001b[0m             \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m         dataset, training_set_metadata = build_dataset(\n\u001b[0m\u001b[1;32m    265\u001b[0m             \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m             \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ludwig/data/preprocessing.py\u001b[0m in \u001b[0;36mbuild_dataset\u001b[0;34m(dataset_df, features, global_preprocessing_parameters, mode, metadata, backend, random_seed, skip_save_processed_input, callbacks)\u001b[0m\n\u001b[1;32m   1172\u001b[0m     \u001b[0mdataset_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfeature_config\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeature_configs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1174\u001b[0;31m         \u001b[0mdataset_cols\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCOLUMN\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCOLUMN\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"build preprocessing parameters\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3805\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3806\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3807\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3808\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3809\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3803\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3804\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3805\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3806\u001b[0m                 \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Order'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# First, let's reset the index of predictions dataframe to have the store id as a column\n",
        "predictions = predictions.reset_index().rename(columns={'index': 'Store_id'})\n",
        "\n",
        "# Now we convert the wide format dataframe to a long format dataframe\n",
        "predictions_melted = predictions.melt(id_vars=['Store_id'], var_name='Date', value_name='Predicted_Sales')\n",
        "\n",
        "# The 'Date' column is currently a string in the format 'Sales_sequence_label_YYYY-MM-DD_predictions', let's extract the date\n",
        "predictions_melted['Date'] = predictions_melted['Date'].str.extract('(\\d{4}-\\d{2}-\\d{2})')\n",
        "\n",
        "# Convert 'Date' column back to datetime format\n",
        "predictions_melted['Date'] = pd.to_datetime(predictions_melted['Date'])\n",
        "\n",
        "# Now, let's merge this with the original dataframe\n",
        "df_analysis = pd.merge(df_predictions, predictions_melted, on=['Store_id', 'Date'], how='left')\n",
        "df_analysis\n"
      ],
      "metadata": {
        "id": "uhbhUvOpalUZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "\n",
        "# Function to calculate RMSE\n",
        "def calculate_rmse(group):\n",
        "    actual = group['Sales']\n",
        "    predicted = group['Sales_predictions']\n",
        "    rmse = sqrt(mean_squared_error(actual, predicted))\n",
        "    return rmse\n",
        "\n",
        "# Apply the function to each group\n",
        "rmse_by_set = df_analysis.groupby('set').apply(calculate_rmse)\n",
        "\n",
        "print(rmse_by_set)"
      ],
      "metadata": {
        "id": "TDLDb2apjPzp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import plotly.express as px\n",
        "\n",
        "# # Select the data for a specific store\n",
        "# store_id = '105'  # replace with your store id\n",
        "# df_store = df_final[df_final['Store_id'] == store_id]\n",
        "\n",
        "# # Create a line plot of sales over time\n",
        "# fig = px.line(df_store, x='Date', y='Sales', title='Sales Over Time for Store {}'.format(store_id))\n",
        "\n",
        "# # Add a line for predicted sales\n",
        "# fig.add_trace(go.Scatter(x=df_store['Date'], y=df_store['Sales_predictions'], mode='lines', name='Predicted Sales'))\n",
        "\n",
        "# fig.show()"
      ],
      "metadata": {
        "id": "yumZJzHG2IRL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_analysis['error'] = df_analysis['Sales'] - df_analysis['Sales_predictions']"
      ],
      "metadata": {
        "id": "9slNl1ct39Vw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "\n",
        "# Assuming 'category' is the name of your category column\n",
        "fig = px.histogram(df_analysis, x=\"error\", color=\"set\", nbins=30,\n",
        "                   labels={\"error\": \"Error\"},\n",
        "                   title=\"Histogram of Error by Category\",\n",
        "                   template='plotly_white')\n",
        "\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "Jf_TpgrliIt9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xEkHo2p9iL2I"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}